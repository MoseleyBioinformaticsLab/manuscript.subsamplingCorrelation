---
title: 'Information-Content-Informed Kendall-tau Correlation: Utilizing Missing Values'
author:
  - Robert M Flight:
      institute: [markey, biochem, rcsirm]
  - Praneeth S Bhatt:
      institute: compeng
  - Hunter NB Moseley:
      email: hunter.moseley@uky.edu
      correspondence: true
      institute: [markey, biochem, rcsirm, ibi, tox]
institute:
  - markey: Markey Cancer Center, University of Kentucky, Lexington, KY 40536, USA
  - biochem: Department of Molecular & Cellular Biochemistry, University of Kentucky, Lexington, KY 40536, USA
  - rcsirm: Resource Center for Stable Isotope Resolved Metabolomics, University of Kentucky, Lexington, KY 40536, USA
  - compeng: Department of Electrical and Computer Engineering, University of Kentucky, Lexington, KY 40506
  - ibi: Institute for Biomedical Informatics, University of Kentucky, Lexington, KY 40536, USA
  - tox: Department of Toxicology and Cancer Biology, University of Kentucky, Lexington, KY 40536, USA
output: 
  rmarkdown::word_document:
    keep_md: true
    pandoc_args:
      - '--lua-filter=scholarly-metadata.lua'
      - '--lua-filter=author-info-blocks.lua'
bibliography: '`r here::here("doc/icikt_references.json")`'
csl: plos-computational-biology.csl
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, 
                      warning = FALSE, 
                      message = FALSE, 
                      fig.width = 8, 
                      fig.height = 6, 
                      fig.process = dn_modify_path,
                      dpi = 600,
                      dev.args = list(png = list(type = "cairo")))
loadd(supp_materials_file)
loadd(supp_tables_file)
loadd(supp_figures_rds)
loadd(supp_tables_rds)
supp_figure_count = readRDS(here::here(supp_figures_rds))
supp_table_count = readRDS(here::here(supp_tables_rds))
loadd(supp_stuff_rda)
load(here::here(supp_stuff_rda))
figure_count = dn_counter$new("Figure ", "_")
table_count = dn_counter$new("Table ", "_")
```

## Abstract

Almost all correlation measures currently available are unable to handle missing values.
Typically, missing values are either ignored completely by removing them or are imputed and used in the calculation of the correlation coefficient.
In both cases, the correlation value will be impacted based on a perspective that missing data represents no useful information.
However, missing values occur in real data sets for a variety of reasons. 
In omics data sets that are derived from analytical measurements, the primary reason for missing values is that a specific measurable phenomenon falls below the detection limits of the analytical instrumentation.
These missing data are not missing at random, but represent some information by their "missingness".
Therefore, we propose an information-content-informed Kendall-tau (ICI-Kt) correlation coefficient that allows missing values to carry explicit information in the determination of concordant and discordant pairs.
With both simulated and real data sets from RNA-seq experiments, we demonstrate that the ICI-Kt allows for the inclusion of missing data values as interpretable information, which allows improved determination of outlier samples prior to differential analysis of omics datasets.
Moreover, our implementation of ICI-Kt uses a mergesort-like algorithm that provides O(nlog(n)) computational performance, a significant improvement over the Kendall-tau correlation available in base R. 
Finally, we show that approximate ICI-Kt correlations can be calculated using smaller feature subsets of large data sets with significant time savings, which has practical computational value when feature sizes are very large.

The ICI-Kt correlation calculation is available in an R package and Python module on GitHub at https://github.com/moseleyBioinformaticsLab/ICIKendallTau and https://github.com/moseleyBioinformaticsLab/icikt, respectively.


## Introduction

Correlation as a measure of the relatedness or similarity of two or more sets of data has a long history, with the mathematical technique being used (and abused) in various scientific fields since it's introduction [@pearson_notes_1920; @rodgers_13_1988].
More recently, correlation calculations have become a cornerstone statistical method in the analysis and integration of varied omics' datasets, especially the big five omics: genomics, transcriptomics, proteomics, metabolomics, and epigenomics [@gu_complexheatmap_2016].
Correlation between biomolecular features (nucleotide variants, RNA transcripts, proteins, metabolites) may be used to evaluate the relationship strength between pairs of the features as well as to detect and derive correlative structures between groups of features [@fukushima_integratedomics_2009].
Moreover, feature-feature correlations can be used to evaluate a dataset based on expected biochemical correlations, for example higher feature-feature correlations within lipid categories versus between lipid categories [@mitchellUntargetedLipidomicsNonSmall2021].
Moreover, correlation is a foundational method for generating biomolecular feature-feature interaction networks, like those provided by STRING [@szklarczyk_string_2017], Genemania [@franz_genemania_2018], and WCGNA [@langfelder_wgcna_2008].
Feature-feature correlation may also be used to inform which features are used for imputation of missing values [@faquih_missingvalueworkflow_2020].

Often, the first step in omics level analyses is to examine the sample-sample (dis)similarities in various ways using exploratory data analysis or EDA.
This can include the examination of decomposition by principal components analysis (PCA), sample-sample pairwise distances, or sample-sample pairwise correlations to highlight biological and batch groups [@10.12688/f1000research.7035.2; @10.12688/f1000research.9005.3; @10.12688/f1000research.8987.2], double check that the appropriateness of planned analyses [@flight_timecourseexploration_2010], and check if any samples should be removed prior to statistical analysis (outlier detection and removal) [@gierlinski_statisticalmodels_2015].
Outlier detection, in particular, is often required for successful omics data analysis, as any misstep during the experimentation, sample collection, sample preparation, or analytical measurement of individual samples can inject high error and/or variance into the resulting data set [@10.12688/f1000research.7035.2; @10.12688/f1000research.9005.3; @10.12688/f1000research.8987.2; @moseleyErrorAnalysisPropagation2013; @gierlinski_statisticalmodels_2015].

```{r add_problemfig}
figure_count$increment("problem")
```

All analytical methods, and in particular the analytical methods used in omics where many analytes are being measured simultaneously; suffer from missing measurements.
Of course some analytes will be missing at random because of random issues with either the instrument or the particular sample, but a larger number of missing measurements are left-censored due to analytes being below the effective detection limit of the instrument, as shown in `r figure_count$label_text("problem")`.
Some analytical instruments are purposely designed to floor measurements when they occur below a certain signal to noise ratio threshold.
Imputation of missing measurements in omics samples is an active area of research, which we will not cover here beyond to say that it is worthwhile and very necessary in many instances.
But when it comes to calculating correlation, there are very few methods that explicitly account for missing data that we know of.
In many cases, missing values may be either ignored and only those measurements that are common across all samples (complete) or common between two samples being compared (pairwise complete) used, or alternatively imputed to zero (or another value) and then included in the correlation calculation.
Each of these are likely to deviate from the real sample-sample correlation values, especially with respect to specific data interpretation perspectives.

```{r problem, dn_id = figure_count}
knitr::include_graphics(here::here("doc/the_problem_3.png"))
```

`r figure_count$label_text("problem")`. 
Graphical description of the left-censored data problem.
An example density plot of the analyte concentrations for a single experimental sample is shown as a solid line. 
The true analyte concentration range covers the full range of the density distribution, with the minimum on the left, and the maximum on the right.
Below certain concentrations, shown by the red line, the instrument returns either missing values (NA), zeros, or some other floored values, resulting in a left-censored distribution.
Above certain concentrations, highlighted by the yellow line, typically the values returned will be identical (or flagged depending on the instrument).
Which analytes will have concentrations in the red region may vary from sample to sample due to the overall sample composition, as well as natural variances (non-systematic error) within each experimental sample.

Assuming that a majority of missing values are not missing at random, but rather result from left-censored distributions due to the analyte being below the effective detection limit (see `r figure_count$label_text("problem")`), we propose that these missing values do in fact encode useful information that can be incorporated into correlation calculations.

To create a correlation measure that is capable of working with missing values, we would not be interested in creating a completely new correlation metric from scratch, but modifying an existing one.
Of the three commonly used correlation measures, Pearson, Spearman, and Kendall-tau, Spearman and Kendall-tau seem most appropriate for modification as they solely use ranks in the calculation of their coefficients.
Modifying Pearson would either involve imputing new values, or finding a way to calculate the covariances **with** missingness included.
While Spearman uses ranks, many of the modifications for handling identical ranks and ties do not seem amenable to working with missing values.
In contrast, Kendall-tau's use of concordant and discordant pair counts seemed most amenable to the creation of new definitions that incorporate missingness while still working within the original definition of the correlation coefficient, as shown below.

In this manuscript, we propose new definitions of concordant and discordant rank pairs that include missing values, as well as methods for incorporating missing values into the number of tied values for the equivalent of the modified Kendall-tau coefficient.
We examine the effect of missing values on various simulated data-sets, comparing our information-content-informed Kendall-tau (ICI-Kt) method with other simpler methods of handling the missing values, namely removing them or imputing them to zero.
Given the detrimental effects of including outlier samples on differential analyses, we also evaluate the ability of ICI-Kt to capture sample-sample pairwise similarities and the determination of outlier samples prior to differential analyses.
Finally, we examine the ability to recapitulate ICI-Kt correlation values calculated on a large feature omics data set using feature subsets, which is useful when the execution time of very large feature data sets becomes computationally prohibitive.

All of the code used for this manuscript is available on zenodo [@flightManuscriptICIKendallTau2022].

## Methods

### Additional Definitions of Concordant and Discordant Pairs to Include Missingness

In the simplest form, the Kendall-tau correlation can be defined as:

$$\tau = \frac{ | pairs_{concordant}  | - | pairs_{discordant}  |}{\left | pairs_{concordant} \right | + \left | pairs_{discordant} \right |}$$
In this case a pair are any two x-y points, $x_i, y_i$ and $x_j, y_j$, with $i \neq j$, composed from two joint random variables X and Y, where $x_i$ represents the *ith value* in X and $y_i$ represents the *ith value* in Y.
In an omics context, X and Y can represent feature vectors for two experimental samples or two specific features across an ordered set of samples.
A concordant pair has the following classical definition:

  * $x_i > x_j$ and $y_i > y_j$ 
  * $x_i < x_j$ and $y_i < y_j$

A discordant pair has the following classical definition [@kendall_newmeasure_1938]:

  * $x_i > x_j$ and $y_i < y_j$
  * $x_i < x_j$ and $y_i > y_j$

We can expand the concordant and discordant pair definitions to include missing values (e.g. `NA` in R). 
Here $!x$ indicates a missing value and & is synonymous with "and".
The information-content-informed concordant pair definitions are below:

  * $x_i > x_j$ and $y_i > y_j$
  * $x_i < x_j$ and $y_i < y_j$
  * $x_i > x_j$ and $y_i \& !y_j$
  * $x_i < x_j$ and $!y_i \& y_j$
  * $x_i \& !x_j$ and $y_i > y_j$
  * $!x_i \& x_j$ and $y_i < y_j$ 
  * $x_i \& !x_j$ and $y_i \& !y_j$ 
  * $!x_i \& x_j$ and $!y_i \& y_j$ 
  
The information content informed discordant pair definitions are below:

  * $x_i > x_j$ and $y_i < y_j$ 
  * $x_i < x_j$ and $y_i > y_j$
  * $x_i > x_j$ and $!y_i \& y_j$ 
  * $x_i < x_j$ and $y_i \& !y_j$
  * $x_i \& !x_j$ and $y_i < y_j$
  * $!x_i \& x_j$ and $y_i > y_j$
  * $x_i \& !x_j$ and $!y_i \& y_j$
  * $!x_i \& x_j$ and $y_i \& !y_j$
  
These additional definitions make it possible to calculate a Kendall-tau correlation that **incorporates missing values**, information-content-informed Kendall-tau (ICI-Kt).

### Considering Ties

Tied values do not contribute to either of the concordant or discordant pair counts, and the original Kendall-tau formula which calculates the tau-a statistic does not consider the presence of tied values.
However, the related tau-b statistic does handle the presence of tied values by adding the tied $x$ and $y$ values to the denominator, and in our special case of missing data, we can add the ties that result from both of $(x_i, x_j)$ and $(y_i, y_j)$ being missing into $n_{xtie}$ and $n_{ytie}$ as well [@kendall_treatment_ties_1945; @kendall_rankcorrelationbook_1948].

$$\tau = \frac{\left | pairs_{concordant} \right | - \left | pairs_{discordant} \right |}{\sqrt{(n_0 - n_{xtie})(n_0 - n_{ytie})}}$$

We can also consider commonly missing values in X and Y specially as well.
In the first instance, we remove those x-y points where **both values** are missing.
We refer to this case as the "local" ICI-Kt correlation.
It is most appropriate for the comparison of only two experimental samples, where we are concerned with what values are present in the two experimental samples, with the odd case of missingness.

The other case, where we leave ties resulting from points with missing X and Y, we refer to as the "global" ICI-Kt correlation.
In this case, every single correlation over multiple comparisons with the same set of features will consider the same number of pair comparisons.
This is useful when analyzing and interpreting correlations from a large number of experimental samples, not just two feature vectors.

### Theoretical Maxima

The "global" case also provides an interesting property, whereby we can calculate the theoretical maximum correlation that would be possible to observe given the lowest number of shared missing values.
This value can be useful to scale the rest of the observed correlation values across many sample - sample correlations, providing a value that scales an entire dataset appropriately.
For any pairwise comparison of two vectors (from experimental samples for example), we can calculate the maximum possible Kendall-tau for that comparison by defining the maximum number of concordant pairs as:

$$tau_{max} = \frac{\left | pairsmax_{concordant} \right |}{
\sqrt{(n_0 - n_{xtie})(n_0 - n_{ytie})}
}$$

Where:

$$pairsmax_{concordant} = n_0 - n_{xtie} - n_{ytie} - n_{tie}$$

Calculating a set of $tau_{max}$ values between all experimental samples, we can take the maximum of those values, and use it to scale all of the obtained Kendall-tau values.

### Implementation Details

We produced an initial reference implementation in R [@rcoreteam_rlanguage_2020] where the various concordant and discordant pair definitions were written as simple logical tests to allow further exploration and validation of faster implementations.
In practice, it is possible to **replace the missing values with a value that is smaller than all of the values in the two sets of values under consideration**, and then do tests of signs to define concordant and discordant pairs (see the definitions of concordant and discordant pairs above).
We note here that this is **not imputation of missing values**

After this initial implementation, we used the *SciPy* [@virtanen_scipy_2020] *kendalltau* code as a model to create a mergesort based implementation that has a complexity of O(nlog(n)), in comparison to the pairwise testing that has a complexity of O(n^2) [@knight_mergesortkendall_1966].
This provides a 460X speedup of the runtime to compare two feature vectors with lengths of 40,000.
In comparison to directly counting the concordant and discordant pairs, some of the values in the mergesort implementation can reach the 32 bit default limit in C++.
Therefore, we used 64 bit integers and floats where necessary in the *Rcpp* code.

C++ (via *Rcpp* [@eddelbuettel_rcppseamless_2011; @eddelbuettel_seamlessbook_2013; @eddelbuettel_extendingrcpp_2018]) and R code implementations are in the src/kendallc.cpp and R/kendalltau.R files of the ICIKendallTau R package, hosted at https://github.com/MoseleyBioinformaticsLab/ICIKendallTau.
The version of the package used in this manuscript is available on zenodo [@flightICIKendallTau2022].

When a large number of samples need to be compared, it may be useful to split the comparisons across compute instances (across hyperthreaded cores, physical cores, or physical compute nodes).
The *furrr* R package makes the definition of compute clusters easy [@vaughanFurrrApplyMapping2021].
For a large correlation matrix computation, we first define the sample-sample comparisons to be performed, then check how many instances of compute are available (defined by a previous call to *furrr*), and finally split the comparisons into a list that can be easily distributed using the *furrr::future_map* function.

We also implemented a package in Python 3 with the same functionality and similar interface to the R package, hosted on GitHub (https://github.com/MoseleyBioinformaticsLab/icikt) and Python Package Index (https://pypi.org/project/icikt).
Appropriate portions of the package were *cythonized* to achieve similar execution performance to the R package.
We used the *multiprocessing* Python package to distribute the sample-sample comparisons calculations across cores with very little overhead.
This package includes both an application programming interface (API) with equivalent parameter options to the R package implementation and a command line interface (CLI) for generating straight-forward correlation matrix analyses without the need to write Python scripts.


### Simulated Data Sets

Simulated feature vectors (analytical samples) are generated by drawing 1000 random values from a log-normal distribution with a mean of 1 and standard deviation (sd) of 0.5 and sorting them in ascending order.
The negative analytical sample has values sorted in descending order.
Missing value indices are generated by randomly sampling up to 499 of the lowest values in each sample.
For the negative sample, the indices are also subtracted from 1000 to cause them to be at the lower end of the feature distribution.
Finally, missing indices were only inserted into one of the two samples being compared before calculating the correlation.
The missing indices are replaced with NA, and then correlations between the analytical samples are calculated.

Another, more realistic, simulated data set is generated by drawing 1000 random values from a log-normal distribution, and adding noise from a normal distribution with a mean of zero and sd of 0.2 to create two statistical samples.
Missing values are created in these statistical samples via two methods: 1) by creating intensity cutoffs from 0 to 1.5 in 0.1 increments, values below the cutoff set to missing or zero depending on the calculation; 2) randomly sampling locations in the two-sample matrix ranging from zero to 300 in increments of 50 and setting the indices to missing or zero.

### Brainson RNA-Seq Data Set

This RNA-Seq dataset is from null and knock-in EGFR mice mutants.
Genotypes include Null (no mutant-EGFR inducible expression), Heterozygous (only one copy of mutant-EGFR), Homozygous (two copies of mutant EGFR).
For each mutant, they were also grown in different ways and sequenced: (1) 2D plates; (2) 3D organoids; (3) cells sorted and selected using FACS; (4) total tumor without sorting.
See [@chenCellularOriginsEGFRDriven2021] for the full experimental details.

### Yeast RNA-Seq Data Set

Summarized gene level counts were obtained from a GitHub project maintained by the Barton group [@coleProfilingDifferentialGene2021].
It should be noted that the data are also available from two figshare repositories [@bartonSNF2KnockoutYeast2015; @bartonWildtypeYeastGene2015].
These data were generated and reported as part of two publications evaluating replicate data and differential gene expression [@gierlinski_statisticalmodels_2015; @schurchHowManyBiological2016].

The original outliers reported by Gierliński et al are based on a combination of median correlations, feature outliers, and RNA-seq coverage.
Given that we want to compare outliers based on correlation, we re-determined outliers using only correlation calculated by replacing zero counts with missing values and calculating sample - sample pairwise Pearson correlations on the raw feature counts using the genes present in both samples.

### Adenocarcinoma Recount RNA-Seq Data Set

We downloaded the recount2 TCGA lung cancer data [@collado-torres_recount2_2017], extracted the scaled counts, and trimmed to the Stage I adenocarcinoma samples, and those genes that have a non-zero count in at least one of the samples.

Pearson and Kendall-tau correlations are calculated with zero, as well as replacing zero values with NA.

### Completeness

As an addition to the correlation, we also calculate the *completeness* between any two samples.
We first measure the number of entries missing in either of the samples being compared, and subtract that from the total number of features in the samples.
This defines how many features are potentially *complete* between the two samples.
This number, over the total number of features defines the *completeness* fraction.

$$comp = \frac{n_{feat} - (miss_i | miss_j)}{n_{feat}}$$


### Subsampling of Features

In addition to using the full set of features to calculate sample-sample correlations, it is possible to select a subsample of features and only use this feature subset to calculate correlations.
Three methods were implemented: 1) random selections; 2) top set of features by variance; and 3) top set of features by variance of principal components.

For (1), random selection, feature subsamples of 1 to 10% by 1% increments, and then in 5% increments to 90% were taken using the *sample* R function.
For (2), selection by variance, feature variances across samples were calculated, and then ranked by the variances.
For (3), selection by variance of the principal components, principal component analysis (PCA) decomposition was performed on the full data set, the variance contribution of each PC calculated, and then the percent variance for each principal component (PC) is used to determine the number of features with high loadings to select from the given PC.
In this feature subsampling approach, weaker PCs contribute proportionately fewer features to the feature subset.

Pearson correlation values were calculated using both raw and log-transformed values, where the starting data had zero values replaced by NA (missing).
In both the raw and log-transformed cases, final missing values were handled by either:
(1) missing (NA) values left as missing (Pearson);
(2) missing (NA) values replaced with 0 (Pearson 0).
In the Pearson case, only features that are non-missing in both samples being compared are used for the correlation (*pairwise.complete.obs*).

### Principal Component Evaluation of Subsample Coverage

The principal component decomposition of the full adenocarcinoma dataset was used to define the loadings for each principal component.
For a given principal component (PC), the sum of the absolute values of the loadings defines the total loadings for that PC.
The absolute values of the loadings for the subsampled features are also summed, and then divided by the total loadings previously calculated using all features.
The loading fraction is calculated for each subsample of features, across all PCs.
The responsible variance for each PC was also calculated as the variance of the scores in each PC.
Further, the Kendall-tau correlation between the loading fraction and the PC variances was calculated.
The median loading fraction across all PCs was also calculated, as well as fractional difference of the median loading fraction to the intended fraction (the number of subsampled features over the total number of features).


### Computing Environment

Most calculations were run on a virtual machine with 80 virtual cores, and 1 TB of RAM.
The virtual machine is running on top of a 50 node cluster, each with 4 10-core processors, 3TB of RAM and an 8TB solid-state-drive array, provided by the Kentucky Research Informatics Cloud (KyRIC).
KyRIC manages the virtual machines via an OpenStack instance.
We used the *drake* package to manage calculation dependencies [@landau_drakepackage_2018].
For the comparisons of time taken using different numbers of samples to evaluate the algorithmic complexity, calculations were run on a single laptop Intel i7 core clocked at 2.2 GHz.

## Results


### Comparison To Other Correlation Measures

We compared the ICI-Kt correlation to both Pearson and regular Kendall-tau-b correlations as calculated by the built-in R functions using simulated data sets with missing values (`r supp_figure_count$label_text(c("kt_pearson", "ici_distribution", "kt_distribution"))`).

We created two samples with 1000 observations each drawn from a log-normal distribution, and sorted in each case.
The *true* correlation for each of the Kendall and Pearson correlations were calculated, and then missingness was introduced in the lower range of values (see Methods).

```{r increment_missing2cor}
figure_count$increment("missing2cor")
```

```{r missing2cor, fig.width = 8, fig.height = 8, dn_id = figure_count}
loadd(realistic_sample_1)
loadd(realistic_sample_2)
loadd(realistic_neg_sample)
ref_pearson = cor(realistic_sample_1, realistic_sample_2)
ref_kendall = ici_kt(realistic_sample_1, realistic_sample_2, "global")[1]

ref_pearson_neg = cor(realistic_sample_1, realistic_neg_sample)
ref_kendall_neg = ici_kt(realistic_sample_1, realistic_neg_sample, "global")[1]

loadd(realistic_na)
n_na = purrr::map_int(realistic_na, length)
loadd(realistic_positive_pearson)
loadd(realistic_positive_kendall)
loadd(realistic_positive_kt)
loadd(realistic_negative_pearson)
loadd(realistic_negative_kendall)
loadd(realistic_negative_kt)

realistic_positive_pearson = realistic_positive_pearson %>%
  dplyr::mutate(type = "Pearson",
                dir = "positive",
                diff = ref_pearson - cor,
                n_na = (x_na + y_na) / 2)

realistic_negative_pearson = realistic_negative_pearson %>%
  dplyr::mutate(type = "Pearson",
                dir = "negative",
                diff = ref_pearson_neg - cor,
                n_na = (x_na + y_na) / 2)

realistic_positive_kendall = realistic_positive_kendall %>%
  dplyr::mutate(type = "Kendall",
                dir = "positive",
                diff = ref_kendall - cor,
                n_na = (x_na + y_na) / 2)

realistic_negative_kendall = realistic_negative_kendall %>%
  dplyr::mutate(type = "Kendall",
                dir = "negative",
                diff = ref_kendall_neg - cor,
                n_na = (x_na + y_na) / 2)

realistic_positive_kt = realistic_positive_kt %>%
  dplyr::mutate(type = "ICI-Kt",
                dir = "positive",
                diff = ref_kendall - cor,
                n_na = (x_na + y_na) / 2)

realistic_negative_kt = realistic_negative_kt %>%
  dplyr::mutate(type = "ICI-Kt",
                dir = "negative",
                diff = ref_kendall_neg - cor,
                n_na = (x_na + y_na) / 2)

positive_df = rbind(realistic_positive_pearson,
                    realistic_positive_kendall,
                    realistic_positive_kt)

negative_df = rbind(realistic_negative_pearson,
                    realistic_negative_kendall,
                    realistic_negative_kt)

use_rows = rep(FALSE, nrow(negative_df))
n_subset = 10000
use_rows[sample(length(use_rows), n_subset)] = TRUE
negative_df = negative_df %>%
  dplyr::mutate(perc_missing = n_na / max(n_na) * 100,
                type = factor(type, levels = c("Kendall", "Pearson", "ICI-Kt"), ordered = TRUE)) %>%
  dplyr::filter(use_rows)
positive_df = positive_df %>%
  dplyr::mutate(perc_missing = n_na / max(n_na) * 100,
                type = factor(type, levels = c("Kendall", "Pearson", "ICI-Kt"), ordered = TRUE)) %>%
  dplyr::filter(use_rows)
pos_diff = ggplot(positive_df, aes(x = n_na, y = diff)) + 
  geom_point() +
  facet_grid(type ~ ., scales = "free") +
  labs(subtitle = "Positive Correlation",
       x = "Number Missing",
       y = "Difference from Reference") +
  scale_y_continuous(labels = label_scientific(digits = 2)) +
  theme(plot.subtitle = element_text(size = 13))
neg_diff = ggplot(negative_df, aes(x = n_na, y = diff)) +
  geom_point() +
  facet_grid(type ~ ., scales = "free") +
  labs(subtitle = "Negative Correlation",
       x = "Number Missing",
       y = "Difference from Reference") +
  scale_y_continuous(labels = label_scientific(digits = 2)) +
  theme(plot.subtitle = element_text(size = 13))

pos_diff + neg_diff
```

`r figure_count$label_text("missing2cor")`. The effect on Kendall, Pearson and ICI-Kt correlations as increasing number of missing values in the bottom half of either sample for both positively and negatively correlated samples.
A subset of `r format(n_subset, big.mark = ",", big.interval = 3L)` points was used for visualization.
Pay attention to the orders of magnitude differences between the y-axis scales.

In `r figure_count$label_text("missing2cor")`, we can see that as missing values are added, only the ICI-Kt correlation values change in any significant way.
As the number of missing values increase, the ICI-Kt values drop or increase by up to 0.2.
Similarly, Pearson correlation is also affected, but the degree of change in the correlation values are much less (notice the orders of magnitude differences in the y-axis scales), on the order of only 0.003 for the positive case and 0.1 for the negative case.
Also, the lack of symmetry in the Pearson negative comparisons is due to the lack of linear correlation between the samples.
These results demonstrate that the ICI-Kt correlation has quantitative sensitivity to missing values over the normal Kendall tau correlation and linear Pearson correlation where points with missing values are ignored (pairwise complete).

### Effect of Left Censoring VS Random Missing Data

```{r increment_figure_left_random}
figure_count$increment("leftcensored")
```

```{r leftcensored, fig.height = 8, fig.width = 8, dn_id = figure_count}
loadd(left_censored_cor)
left_censored_cor = left_censored_cor %>%
  dplyr::mutate(which2 = dplyr::case_when(
    which %in% "ici" ~ "ICI-Kt",
    which %in% "kendall" ~ "Kendall",
    which %in% "kendall_0" ~ "Kendall-0",
    which %in% "pearson" ~ "Pearson",
    which %in% "pearson_0" ~ "Pearson-0"
  ))

loadd(random_censored_cor)

random_censored_cor = random_censored_cor %>%
  dplyr::mutate(censoring = "random") %>%
  dplyr::filter(n_na > 0) %>%
  dplyr::mutate(which2 = dplyr::case_when(
    which %in% "ici" ~ "ICI-Kt",
    which %in% "kendall" ~ "Kendall",
    which %in% "kendall_0" ~ "Kendall-0",
    which %in% "pearson" ~ "Pearson",
    which %in% "pearson_0" ~ "Pearson-0"
  ))

loadd(logtransform_censored_cor)
logtransform_censored_cor = logtransform_censored_cor %>%
  dplyr::mutate(censoring = "random") %>%
  dplyr::filter(n_na > 0) %>%
  dplyr::mutate(which2 = dplyr::case_when(
    which %in% "ici" ~ "ICI-Kt",
    which %in% "kendall" ~ "Kendall",
    which %in% "kendall_0" ~ "Kendall-0",
    which %in% "pearson" ~ "Pearson",
    which %in% "pearson_0" ~ "Pearson-0"
  ))


random_plot = ggplot(random_censored_cor, aes(x = n_na, y = cor)) +
  geom_sina(aes(group = n_na)) +
  facet_wrap(~ which2, nrow = 1, scales = "free_y") +
  labs(x = "Number Missing", y = "Correlation") +
  cowplot::panel_border()

rp_build = ggplot_build(random_plot)
rp_breaks = rp_build$layout$panel_params[[1]]$x$get_breaks()
rp_lim = rp_build$layout$panel_params[[1]]$x$get_limits()

left_plot = ggplot(left_censored_cor, aes(x = n_na, y = cor)) + 
  geom_point() + 
  facet_wrap(~ which2, nrow = 1, scales = "free_y") +
  labs(x = "Number Missing", y = "Correlation") +
  scale_x_continuous(breaks = c(0, 100, 200)) +
  cowplot::panel_border() 

log_plot = ggplot(logtransform_censored_cor, aes(x = n_na, y = cor)) +
  geom_point() +
  facet_wrap(~ which2, nrow = 1, scales = "free_y") +
  labs(x = "Number Missing", y = "Correlation") +
  scale_x_continuous(breaks = c(0, 100, 200)) +
  cowplot::panel_border()

(left_plot / log_plot / random_plot) + plot_annotation(tag_levels = "A")
```

`r figure_count$label_text("leftcensored")`. Effect of introducing missing values from a cutoff (A & B) or randomly (C) on different measures of correlation, including ICI-Kt, Kendall with pairwise complete, Kendall replacing missing with 0, Pearson with pairwise complete, and Pearson replacing missing with 0.
A) Missing values introduced by setting an increasing cutoff.
B) Missing values introduced by setting an increasing cutoff, and then log-transforming the values before calculating correlation.
C) Missing values introduced at random.
For the random case, each sample of random positions was repeated 100 times.

`r figure_count$label_text("leftcensored")` demonstrates the effect of introducing left-center versus random missingness in five different measures of correlation, including the ICI-Kt, the normal Kendall tau with pairwise complete, the normal Kendall tau replacing missing with 0, Pearson with pairwise complete, and Pearson replacing missing with 0.
The ICI-Kt correlation demonstrates a slight increase from the starting 0.86 correlation value with growing left-centered missingness caused by a slight reinforcement of the correlation, while with **growing random missingness**, the ICI-Kt correlation drops precipitously due to the large increase in discordant pairs caused by the random missing values.
The normal Kendall tau correlation with pairwise complete has a small decrease in the correlation value with growing left-centered missingness caused by a loss of supporting pairs, while this correlation has a near constant average value with growing random missingness.
The normal Kendall tau correlation replacing missing with 0 has identical behavior to the ICI-Kt correlation.
In contrast to ICI-Kt, the Pearson correlation calculated using only pairwise complete entries is **constant** over growing left-centered and random missingness.
When replacing missing values with zero, Pearson correlation demonstrates a small decrease in the correlation value with growing left-centered missingness due to the zero values causing some deviation from linearity. 
Pearson correlation drops precipitously with growing random missingness with a magnitude similar to the ICI-Kt and normal Kendall tau replacing missing with 0.
Overall, the ICI-Kt and the normal Kendall-tau replacing missing with zero have the desirable characteristics of maintaining the correlation with growing left-centered missing **while sharply dropping the correlation** with growing random missingness.
In a naive treatment of the left-centered missing data, if the values below the cutoff are set to missing followed by log-transforming the values and subsequently setting missing values to 0, then the Kendall tau correlation replacing missing with 0 will show some very odd patterns at low intensity cutoffs due to the introduction of discordant pairs.
Likewise, Pearson correlation replacing missing with 0 shows a parabolic effect with increasing missing values.

We note here that the typical way we've observed of handling missing data in correlation calculations is to ignore them completely and use the pairwise complete cases to calculate the Pearson correlation coefficient.
As shown in `r figure_count$label_text("leftcensored")`C, this results in a complete misestimation of the changed correlative structure introduced by missing at random (MAR) entries.
ICI-Kt, in contrast, incorporates the missingness in a sensical way, and the resulting correlation values fall as MAR entries are introduced.

### Algorithmic Performance

We compared the performance of our *Rcpp* *mergesort* implementation to the base R *cor* function using both "pearson" and "kendall" methods on a single core with increasing numbers of features.

```{r setup_perfplot}
figure_count$increment("singleperf")
```

`r figure_count$label_text("singleperf")` shows that the "kendall" method is the slowest by far.
Zoomed out (inset), the ICI-Kt appears as fast as using "pearson", but upon zooming in, it's possible to see that ICI-Kt is using increasing amounts of time much faster than "pearson".
In fact, regressing the time to number of samples using a formula with the expected algorithmic complexity, "pearson" shows O(n), ICI-Kt is O(nlog(n)), and "kendall" is O(n^2) (see `r supp_figure_count$label_text("complexity")`).

```{r singleperf, dn_id = figure_count}
single_core_perf = readRDS(here::here("doc", "single_core_perf.rds"))
single_core_perf = single_core_perf %>%
  dplyr::mutate(method2 = dplyr::case_when(
    method %in% "ici_kt" ~ "ICIKendallTau::ici_kt()",
    method %in% "r_pearson" ~ 'stats::cor(method = "pearson")',
    method %in% "r_kendall" ~ 'stats::cor(method = "kendall")'
  )) %>%
  dplyr::mutate(method = method2)
s_perf_plot = ggplot(single_core_perf, aes(x = n, y = time, color = method)) +
  geom_line(size = 2) + 
  coord_cartesian(ylim = c(NA, 0.002)) + 
  theme(legend.position = c(0.6, 0.2)) +
  labs(x = "Number of Features", y = "Time (s)")
#s_perf_plot

mod_perf = dplyr::filter(single_core_perf, grepl("ici_kt", method))
mod_perf$time = mod_perf$time + 0.015
single_no_ici = dplyr::filter(single_core_perf, !(grepl("ici_kt", method)))
core_perf2 = bind_rows(
  mod_perf,
  single_no_ici
)
inset_perf = ggplot(core_perf2, aes(x = n, y = time, color = method)) +
  geom_line(size = 1.5) +
  theme(legend.position = "none",
        axis.ticks.x = element_blank(),
        axis.text.x = element_blank()) +
  labs(x = "", y = "")

s_perf_plot + inset_element(inset_perf, 0.1, 0.72, 1, 1)
```

`r figure_count$label_text("singleperf")`. Comparison of the *Rcpp* *mergesort* *ici_kt*, and base R's *cor* function using the "pearson" and "kendall" methods as the number of features are increased from 100 to 5000.
Inset is the expanded view showing the full range of computation time in seconds.


### Multi-Processing Performance

In addition to an evaluation of the mergesort performance, we also wanted to evaluate the multi-processing performance.
For this, we ran with small numbers of samples **without** parallelization enabled, and then with larger numbers of samples **with** parallelization enabled.

```{r increment_dependence}
figure_count$increment("multiperformance")
```

```{r multiperformance, dn_id = figure_count}

loadd(combined_big)
combined_big = combined_big %>%
  dplyr::mutate(set = "large")

ggplot(combined_big, aes(x = n_sample, y = log2(time))) + 
  geom_line() +
  labs(x = "Number of Samples",
       y = "Log2(Time) (s)")
```

`r figure_count$label_text("multiperformance")`. 
Time taken by ICI-Kt as a function of the number of samples with multi-processing at the R level, using 80 cores.

As samples are added, the run time quickly increases logarithmically, similar to increasing samples on a single core (see `r figure_count$label_text("multiperformance")`).


### Utility in Large Omics' Data Sets

#### Detecting Outlier Samples

```{r setting_up_outliers}
figure_count$increment("yeast_outliers")
table_count$increment("yeast_outliers")

figure_count$increment("brainson_outliers")
table_count$increment("brainson_outliers")

figure_count$increment("adeno_outliers")
table_count$increment("adeno_outliers")

outlier_figure_text = figure_count$label_text(c("yeast_outliers",
                                                "brainson_outliers",
                                                "adeno_outliers"))
outlier_table_text = table_count$label_text(c("yeast_outliers",
                                              "brainson_outliers",
                                              "adeno_outliers"))
```

We analyzed three RNA-Seq datasets for possible outliers using a variety of  different correlation and correlation-related metrics: (1) ICI-Kt; (2) ICI-Kt scaled by *completeness* (see Methods); (3) Pearson correlation; (4) Pearson using pairwise complete features; (5) Pearson on log(value + 1); (6) Pearson on log(value); and (7) Kendall-tau.
We primarily concentrate on the ICI-Kt, ICI-Kt * completeness, and Pearson log(x + 1) here, but all outliers by method are shown in the Supplemental materials (`r supp_figure_count$label_text(c("yeast_outliers", "adeno_outliers"))`, `r supp_table_count$label_text(c("yeast_outliers", "brainson_outliers"))`).
Additionally, we compared how the outliers change if we require that a feature is present in at least a certain fraction of samples of a class with each different correlation measure (`r supp_figure_count$label_text(c("yeast_by_method", "adeno_differences"))`).
For each dataset and correlation-related metric, the median correlation for a sample was calculated amongst the samples for each sub-group of samples corresponding to an experimental condition of interest (disease, mutant, how cells were grown).

```{r load_yeast_outliers}
compare_yeast_main = c("icikt", "icikt_complete", "pearson_log1p")
```

```{r yeast_outliers, dn_id = figure_count}
yeast_single %>%
  add_method() %>%
  dplyr::filter(which %in% compare_yeast_main) %>%
  ggplot(aes(x = sample_class, y = med_cor, color = outlier, group = sample_class)) +
  geom_sina() +
  facet_wrap(~ method, nrow = 1) +
  labs(x = "Sample Class", y = "Median Correlation") +
  theme(legend.position = c(0.75, 0.2))
```

`r figure_count$label_text("yeast_outliers")`.
Median correlations for each of the yeast RNA-Seq sample to all other samples in the same group, using either ICI-Kt, ICI-Kt * completeness or Pearson Log(x + 1) correlation.


`r table_count$label_text("yeast_outliers")`.
Yeast dataset median correlation values and outlier determination for each outlier from each of the correlation methods.

```{r yeast_outlier_table}
yeast_table = compare_outlier_tables(yeast_single, compare_yeast_main, sort_var = "pearson_log1p")
yeast_ft_out = yeast_table %>%
  set_nice_widths() %>%
  put_outlier_right()
yeast_ft_out
```


`r figure_count$label_text("yeast_outliers")` visualizes the sample-specific median of each correlation-related metric calculated from the Yeast RNA-Seq data set. 
`r table_count$label_text("yeast_outliers")` lists the outliers detected based on each sample-specific median metric value.  
In this example, ICI-Kt shows superior sensitivity for outlier detection as compared to the other metrics and is likely related to the increased spread of median metric values as compared to Pearson.
We also note that these outliers seem to be a superset of the outliers noted by Gierliński et al. (see `r supp_figure_count$label_text("yeast_outliers")` and `r supp_table_count$label_text("yeast_outliers")`).


```{r brainson_outliers, dn_id = figure_count}
compare_brainson_main = c("icikt", "icikt_complete", "pearson_log1p")
brainson_single %>%
  add_method() %>%
  dplyr::filter(which %in% compare_brainson_main) %>%
  ggplot(aes(x = sample_class, y = med_cor, color = outlier, group = sample_class)) +
  geom_sina() + 
  facet_wrap(~ method, nrow = 1) +
  labs(x = "Sample Class", y = "Median Correlation") +
  theme(legend.position = c(0.75, 0.2))
```

`r figure_count$label_text("brainson_outliers")`. 
Median correlations for each of the Brainson RNA-Seq samples to all other samples in the same group, using either ICI-Kt, ICI-Kt * completeness or Pearson Log(x + 1) correlation.

`r table_count$label_text("brainson_outliers")`.
Brainson dataset median correlation values and outlier determination for each outlier from each of the correlation methods.

```{r brainsonseq_table}
brainson_table = compare_outlier_tables(brainson_single, compare_brainson_main, sort_var = "pearson_log1p")

brainson_ft_out = brainson_table %>%
  set_nice_widths(sample_width = 1.5) %>%
  put_outlier_right()
brainson_ft_out
```

`r figure_count$label_text("brainson_outliers")` visualizes the sample-specific median of each metric calculated from the Brainson RNA-Seq data set.
Likewise, `r table_count$label_text("brainson_outliers")` lists the outliers detected based on each metric.
In this example, Pearson shows superior sensitivity to outlier detection, likely due to the larger spread in median Pearson correlation values.

```{r adeno_outliers, dn_id = figure_count}
compare_adeno_main = c("icikt", "icikt_complete", "pearson_log1p")
adeno_single %>%
  add_method() %>%
  dplyr::filter(which %in% compare_adeno_main) %>%
  ggplot(aes(x = sample_class, y = med_cor, color = outlier, group = sample_class)) +
  geom_sina() + 
  facet_wrap(~ method, nrow = 1) +
  labs(x = "Sample Class", y = "Median Correlation") +
  theme(legend.position = c(0.75, 0.2))
```

`r figure_count$label_text("adeno_outliers")`.
Median correlations for each of the TCGA adenocarcinoma RNA-Seq samples to all other samples in the same group, using either ICI-Kt, ICI-Kt * completeness or Pearson Log(x + 1) correlation.

`r table_count$label_text("adeno_outliers")`.
TCGA adenocarcinoma dataset median correlation values and outlier determination for each outlier from each of the correlation methods.

```{r adeno_table}
adeno_table = compare_outlier_tables(adeno_single, compare_adeno_main, sort_var = "pearson_log1p")
adeno_ft_out = adeno_table %>%
  set_nice_widths() %>%
  put_outlier_right()
adeno_ft_out
```

`r figure_count$label_text("adeno_outliers")` visualizes the sample-specific median metric value calculated from the TCGA RNA-Seq data set, with `r table_count$label_text("adeno_outliers")` listing the outliers detected from each metric.
In this example, the ICI-Kt * completeness correlation demonstrated superior sensitivity for outlier detection, likely due to its better sensitivity to measurement completeness.
The wider spread of measurement completeness is expected, since TCGA is an aggregate of samples collected from various human cancer patents as compared to the first two examples which were collected from specific experiments in cell culture (`r supp_table_count$label_text("adeno_mad")`).
The wider spread of measurement completeness is expected, since TCGA is an aggregate of samples collected from various human cancer patients as compared to the first two examples which were collected from specific experiments in cell culture. 
However, the outliers detected are not a complete superset of the outliers detected by ICI-Kt and Pearson, probably due to the integration of completeness and correlation.


#### Feature Subsets for Extremely Large Datasets


```{r load_data}
loadd(transcript_data)
loadd(ref_cor)
figure_count$increment("icisubsampling")
```

```{r icisubsampling, fig.height = 8, fig.width = 5, dn_id = figure_count}

loadd(run_random_select_random_fraction_0.01)
loadd(run_random_select_random_fraction_0.1)
loadd(run_random_select_random_fraction_0.3)
diff_vals = data.frame(ref = extract_data(ref_cor),
                       f_01 = 
extract_data(run_random_select_random_fraction_0.01),
                     f_1 = extract_data(run_random_select_random_fraction_0.1),
                     f_3 = extract_data(run_random_select_random_fraction_0.3))
diff_vals = diff_vals %>%
  dplyr::mutate(diff_1 = f_01 - ref,
                diff_10 = f_1 - ref,
                diff_30 = f_3 - ref)
ref_f1_f3 = 
  ((ggplot(diff_vals, aes(x = ref, y = f_01)) + geom_point(alpha = 0.1) +
     labs(x = "All Features", y = "1% Features") +
  coord_equal() +
    geom_abline(slope = 1, color = "red")) |
  (ggplot(diff_vals, aes(x = diff_1)) +
     geom_histogram(bins = 100) +
     labs(x = "Correlation Residual") +
     coord_cartesian(xlim = c(-0.03, 0.03)) +
     scale_y_continuous(expand = expansion(mult = 0)) +
     geom_vline(xintercept = 0, color = "red"))) /
  ((ggplot(diff_vals, aes(x = ref, y = f_1)) + geom_point(alpha = 0.1) +
     labs(x = "All Features", y = "10% Features") +
     coord_equal() +
      geom_abline(slope = 1, color = "red")) | 
  (ggplot(diff_vals, aes(x = diff_10)) +
     geom_histogram(bins = 100) +
     labs(x = "Correlation Residual") +
     coord_cartesian(xlim = c(-0.03, 0.03)) +
     scale_y_continuous(expand = expansion(mult = 0)) +
     geom_vline(xintercept = 0, color = "red"))) /
  ((ggplot(diff_vals, aes(x = ref, y = f_3)) + geom_point(alpha = 0.1) +
     labs(x = "All Features", y = "30% Features") +
     coord_equal() +
      geom_abline(slope = 1, color = "red")) +
  (ggplot(diff_vals, aes(x = diff_30)) +
     geom_histogram(bins = 100) +
     labs(x = "Correlation Residual") +
     coord_cartesian(xlim = c(-0.03, 0.03)) +
     scale_y_continuous(expand = expansion(mult = 0)) +
     geom_vline(xintercept = 0, color = "red")))

ref_f1_f3
```

`r figure_count$label_text("icisubsampling")`. Sample-sample ICI-Kt correlations using all features compared with 1%, 10% and 30% random subsets of features. 
Left: The sample-sample correlations using all features are plotted against the sample-sample correlations using a random subset. Red line indicates perfect agreement. 
Right: Histogram of the residual differences of the sample-sample correlations, where the difference is the (random subset - all features).

Given the length of time it takes to run the calculations for larger datasets (in particular RNA-Seq data), we wondered if "good enough" results could be obtained using subsamples of the features across the samples.
Our starting data is the same set of stage I (I, Ia, and Ib) adenocarcinoma tumor and normal tissue RNA-Seq samples from the *recount2* project used for outlier detection, with `r nrow(transcript_data)` features that have a non-zero value in at least one sample, and `r ncol(transcript_data)` samples.

In our original *Rcpp* implementation using pairwise comparisons, the adenocarcinoma pairwise comparisons took 6.7 hours, on an 80 core virtual machine.
With the mergesort implementation, that time was greatly reduced to just over a minute (69 seconds).
However, given that there may still be cases where the number of comparisons are so large that run time is still a concern, we investigated the effect of estimating sample-sample correlations using a subset of the features.

`r figure_count$label_text("icisubsampling")` compares the sample-sample correlations from a random percent subsample of features to those obtained using all of the features.
Both the pairwise plot (left) and histogram of residual differences (right) show that the correlations become much closer to those obtained when using all of the features as the percentage of subsampled features is increased.
However, there is a consistent positive bias in the estimate, regardless of the number of subsamples used (see also `r supp_figure_count$label_text("icikt_subsampling")`).
This bias is small, because we are comparing the **raw** correlation values, and not the rescaled values.
When the rescaled values (using the maximum correlation) are compared, the positive bias becomes larger, due to the differences in the maximum correlation (results not shown).

For the Pearson and Kendall correlation methods, the subsampled correlation results are almost identical to the ICI-Kt, with slightly higher residual differences for both Pearson and Kendall over ICI-Kt, and then lower residuals if the missing values (NA)  from log-transformation of zeros are replaced with zero (see `r supp_figure_count$label_text(c("pearson_subsampling", "compare_overrange"))`).

```{r setup_nonlog}
figure_count$increment("pearson_nolog")
```

We also tested Pearson correlation subsets without log-transforming the count data first.
As shown in `r figure_count$label_text("pearson_nolog")`, as well as Figures `r supp_figure_count$just_count("pearson_subsampling_nolog")` and `r supp_figure_count$just_count("pearson_sub_overrange_nolog")`, when the transcriptomics data is not log-transformed, Pearson correlation using subsets of features deviates wildly from those obtained using the full data set, much more than ICI-Kt or any of the other methods used.

```{r pearson_nolog, fig.height = 10, fig.width = 10, dn_id = figure_count}
focus_colors = use_colors[c("ICI-Kt", "Pearson", "Pearson NoLog")]
combined_focus = all_combined %>%
  dplyr::filter(method %in% c("ICI-Kt", "Pearson", "Pearson NoLog"))
combined_focus_nolog = combined_focus %>%
  dplyr::filter(!(method %in% "Pearson NoLog"))

compare_focus = (ggplot(combined_focus, aes(x = fraction, y = median, color = method)) +
                   geom_line() +
                   scale_color_manual(values = focus_colors) +
                   labs(x = "Fraction of Features", y = "Median Correlation Differences") +
                   theme(legend.position = "none")) /
                   (ggplot(combined_focus, aes(x = fraction , y = sd, color = method)) +
                      geom_line() +
                      scale_color_manual(values = focus_colors) +
                      labs(x = "Fraction of Features", y = "Correlation Differences SD") +
                      theme(legend.position = "none"))

compare_focus_small = (ggplot(combined_focus_nolog, aes(x = fraction, y = median, color = method)) +
  geom_line() +
    scale_color_manual(values = focus_colors) +
  labs(x = "Fraction of Features", y = "Median Correlation Differences") +
    theme(legend.position = c(0.6, 0.4))) /
  (ggplot(combined_focus_nolog, aes(x = fraction, y = sd, color = method)) +
  geom_line() +
    scale_color_manual(values = focus_colors) +
  labs(x = "Fraction of Features", y = "Correlation Differences SD") +
    theme(legend.position = "none"))

compare_focus | compare_focus_small
```

`r figure_count$label_text("pearson_nolog")`.
Median (top) and standard deviation (SD, bottom) of correlation differences using subsets as the fraction of features used increases, for different methods, including ICI-Kt, Pearson on log-transformed data (Pearson), and Pearson without log-transforming the data (Pearson NoLog).
Left shows all three methods compared to each other, while the right omits Pearson NoLog to show the much smaller ranges of values for the other two methods in comparison to the Pearson NoLog.

```{r setup_pca_variancefig}
figure_count$increment("pcavardifference")
```

In addition to the random feature subsamples, we also implemented feature selection methods based on loading contributions to each PC, as well as feature variances in the full data set (see Methods).
As shown in `r figure_count$label_text("pcavardifference")`, both of these feature selection methods perform extremely poorly, even at the relatively large fraction of 50% of the features.

```{r pcavardifference, dn_id = figure_count}
loadd(run_nonrandom_select_nonrandom_fraction_0.5_var_select)
loadd(run_nonrandom_select_nonrandom_fraction_0.5_pca_select)
diff_var = data.frame(ref = extract_data(ref_cor),
                         f_50 = 
                           extract_data(run_nonrandom_select_nonrandom_fraction_0.5_var_select)) %>%
  dplyr::mutate(diff = f_50 - ref)
diff_pca = data.frame(ref = extract_data(ref_cor),
                      f_50 = extract_data(run_nonrandom_select_nonrandom_fraction_0.5_pca_select)) %>%
  dplyr::mutate(diff = f_50 - ref)

var_diff = ggplot(diff_var, aes(x = ref, y = f_50)) +
  geom_abline(slope = 1, color = "red") +
  geom_point(alpha = 0.1) +
  coord_equal() +
  labs(x = "All Features",
       y = "50% Features by Variance")
pca_diff = ggplot(diff_pca, aes(x = ref, y = f_50)) +
  geom_abline(slope = 1, color = "red") +
  geom_point(alpha = 0.1) +
  coord_equal() +
  labs(x = "All Features",
       y = "50% Features by PCA")
var_dist = ggplot(diff_var, aes(x = diff)) + 
  geom_histogram(bins = 100) + 
  labs(x = "Correlation Residual")
pca_dist = ggplot(diff_pca, aes(x = diff)) +
  geom_histogram(bins = 100) +
  labs(x = "Correlation Residual")

nonrandom_plot = (var_diff | var_dist) / (pca_diff | pca_dist)
nonrandom_plot
```

`r figure_count$label_text("pcavardifference")`. Sample-sample ICI-Kt correlations using all features compared with 50% non-random subsets of features. 
Left: The sample-sample correlations using all features are plotted against the sample-sample correlations using 50% of features chosen by variance contribution or PCA. Red line indicates perfect agreement. 
Right: Histogram of the residual differences of the sample-sample correlations, where the difference is the (subset - all features).

```{r setup_pcaeval}
figure_count$increment("pcaeval")
```

Outside of the differences between the subset and full set of correlations, we also evaluated each of the feature subsets using the correlation between loading fraction and principal component contributed variance (see `r figure_count$label_text("pcaeval")` A & B), and the difference between the median loading fraction and the intended fraction (C & D).

```{r pcaeval, dn_id = figure_count}
loadd(pca_eval_summary)
pca_eval_summary = pca_eval_summary %>%
  dplyr::mutate(Method = dplyr::case_when(
    grepl("pca", type) ~ "PCA",
    grepl("random", type) ~ "Random",
    grepl("var", type) ~ "Variance"
  ))
#pca_eval_summary$Method = factor(pca_eval_summary$Method, levels = c("Random", "PCA", "Variance"), ordered = TRUE)
loadd(all_pca_eval)
pca_eval_50 = all_pca_eval %>%
  dplyr::filter(frac == 0.5) %>%
  dplyr::mutate(percent2 = percent * 100)

rand_eval = pca_eval_50 %>%
  dplyr::filter(type %in% "random")
rand_kt = ici_kt(rand_eval$percent, rand_eval$selected_frac)[[1]]
rand_labels = data.frame(label = c(paste0("Correlation: ", format(rand_kt, digits = 2)),
                                   paste0("Fraction: 0.5")),
                         x = c(2.5, 2.5),
                         y = c(0.502, 0.504),
                         hjust = 0)
rand_example = ggplot(rand_eval, aes(x = percent2, y = selected_frac)) +
  geom_point(alpha = 0.5) +
  labs(x = "% PC Variance", y = "Loading Fraction") +
  geom_text(data = rand_labels, aes(x = x, y = y, label = label, hjust = hjust))

pca_eval = pca_eval_50 %>%
  dplyr::filter(type %in% "pca")
pca_kt = ici_kt(pca_eval$percent, pca_eval$selected_frac)[[1]]

pca_labels = data.frame(label = c(paste0("Correlation: ", format(pca_kt, digits = 2)),
                                   paste0("Fraction: 0.5")),
                         x = c(2.5, 2.5),
                         y = c(0.8, 0.85),
                         hjust = 0)
pca_example = ggplot(pca_eval, aes(x = percent2, y = selected_frac)) +
  geom_point(alpha = 0.5) +
  labs(x = "% PC Variance", y = "Loading Fraction") +
  geom_text(data = pca_labels, aes(x = x, y = y, label = label, hjust = hjust))

example_plots = rand_example / pca_example


e_kt = ggplot(pca_eval_summary, aes(x = frac, y = kt, color = Method)) +
  geom_point() +
  labs(x = "Subsample Fraction", y = "Correlation of Loading Fraction with PC Variance") +
  theme(legend.position = "none")

e_diff = ggplot(pca_eval_summary, aes(x = frac, y = diff_perc, color = Method)) + 
  geom_point() +
  labs(x = "Subsample Fraction", y = "Percent Median Loading Fraction Difference") +
  theme(legend.position = c(0.5, 0.8))

eval_plot = (example_plots | e_kt | e_diff) + plot_annotation(tag_levels = "A")
eval_plot
```

`r figure_count$label_text("pcaeval")`. 
A) Random feature subsample of 0.5, with % principal component variance against the loading fraction. 
B) Variance informed feature subsample of 0.5, % principal component variance against the loading fraction. 
C) Subsample feature fraction plotted against the correlation of the loading fraction with PC variance for each type of subsampling.
D) Subsample feature fraction  plotted against the percent difference of the median loading fraction to the intended loading fraction, which is also the subsample fraction.

`r figure_count$label_text("pcaeval")` shows that for both the PCA and variance informed subsampling methods, there is a relationship between loading fraction and the percent PC variance.
In contrast, the random subsampling shows no relationship of fraction to percent PC variance.
The actual loading fraction covered by the subsample also varies widely from the intended fraction for the PCA and variance informed subsampling, while the random subsample fraction remains close to the intended fraction, with some minor deviation at the very low fractions.

## Discussion and Conclusion

Left-censored distributions in analytical measurements of biological samples are common in biological and biomedical research, because of detection limits of the analytical instrumentation, which produces missing measurement values for all the analytes below these detection limits.
As far as we are aware, previous efforts in this area are concerned with either 1: attempting to come up with better imputation methods prior to calculating correlation values; or 2: finding ways to still estimate the correlation in the face of missing values, generally by finding maximum likelihood estimates.
In the case of (1), there are many imputation methods, and new methods are still being developed, although they tend to be new combinations of old methods to handle the various types of missing values.
For (2), the maximum likelihood methods generally apply to Pearson and similar types of correlation, as they benefit from the use of regression in the presence of missing data.
Alvo and Cabilio's work from 1995 [@alvoRankCorrelationMethods1995] is one of the only works we are aware of that attempts to create a general framework for rank based statistics in the presence of missing data.
But, in our understanding their framework applies to data that is missing at random versus non-random missing-values, as is the case for analytes that are below the detection limit.
Additionally, there does not appear to be a software implementation of Alvo and Cabilio's method available.
In the case of using sample-sample correlation to detect outliers, imputation does not solve any of the issues related to discovering outliers, as it should be applied **after** outlier samples are removed, otherwise the imputed values may not be useful.
As far as we know, information-content-informed Kendall-tau (ICI-Kt) is the first correlation method that explicitly attempts to utilize non-random missing values that occur due to being below the detection limit.
ICI-Kt **explicitly** treats left-censored missing values as correlative information while preserving the full deleterious effects of non-random missing values on the correlation metric.
Moreover, the ICI-Kt can be combined with measurement completeness to create a composite metric that is quite sensitive to overall data quality on a sample-specific level.
Also, this ICI-Kt * completeness metric may have applications in cluster detection of single-cell omics data sets.

The implementations of the ICI-Kt in the presented R and Python packages provide a rich set of options for customizing the correlation calculation for a variety of use-cases and interpretations.
These packages handle missing values in log-transformed data in a safe manner and have O(nlogn) performance, making them computationally practical for real-world omics data sets.
Also, these packages provide multiprocessing implementations that take full advantage of modern multi-core central processing units.
Furthermore, given the high amount of correlated variance in most real-world high-feature data sets, we demonstrate that random feature subsetting can be utilized to effectively estimate correlation for very large data sets or in situations where sub-second computational performance is needed for non-large data sets.
However, care must be taken both in transforming data if using a method with an expectation of linearity, and selecting subsets of features.
When using Pearson correlation, the log-transformation of RNA-seq data is absolutely necessary when using feature subsets.
From the results presented here, random feature subsetting was superior to variance-selective feature subsetting.

As demonstrated with the three RNA-Seq datasets analyzed here, the "best" correlation-related metric will likely depend on the specific dataset and the specific data analysis step.
Many factors affect this, especially correlation linearity and the modality of measurement value distributions.
We would humbly suggest that for most omics datasets, the application of several correlation-related metrics simultaneously would be the best approach for outlier detection in quality control and quality assessment steps.
Where one metric lacks outlier detection sensitivity, another metric will prove sensitive.
Therefore, ICI-Kt and composite metrics derived from it should be considered as useful additions to the omics data analysis toolkit.

## Author Contributions

RMF wrote the code in the ICIKendallTau R package, tested the ICI-Kt correlation code, and wrote all of the analysis code for this manuscript. PSB wrote the icikt Python package.
HNBM conceived of the ICI-Kt correlation metric, provided input into code structures, and supervised the analyses and interpretation of results.
All authors contributed to the writing of the manuscript.


## Acknowledgements

The results shown here are in whole or part based upon data generated by the TCGA Research Network: https://www.cancer.gov/tcga.
This work was supported in part by grants NSF 2020026 (PI Moseley), NSF ACI1626364 (Griffioen, Moseley), P30 CA177558 (PI Evers) via the Markey Cancer Center Biostatistics and Bioinformatics Shared Resource Facility (MCC BB-SRF), P20 GM121327 (PD St. Clair), and P42 ES007380 (PI Pennell) via the Data Management and Analysis Core (DMAC).

## References
